{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202506d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import timeit\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4853bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor(0,dtype=torch.float32)\n",
    "for i in range(1000):\n",
    "    s += torch.tensor(0.01,dtype=torch.float32)\n",
    "print(s)\n",
    "s = torch.tensor(0,dtype=torch.float16)\n",
    "for i in range(1000):\n",
    "    s += torch.tensor(0.01,dtype=torch.float16)\n",
    "print(s)\n",
    "s = torch.tensor(0,dtype=torch.float32)\n",
    "for i in range(1000):\n",
    "    s += torch.tensor(0.01,dtype=torch.float16)\n",
    "print(s)\n",
    "s = torch.tensor(0,dtype=torch.float32)\n",
    "for i in range(1000):\n",
    "    x = torch.tensor(0.01,dtype=torch.float16)\n",
    "    s += x.type(torch.float32)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 10, bias=False)\n",
    "        self.ln = nn.LayerNorm(10)\n",
    "        self.fc2 = nn.Linear(10, out_features, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "#         import ipdb\n",
    "#         ipdb.set_trace()\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.ln(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel(256, 256)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_input = torch.rand((4,256), dtype=torch.float32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "    model(rand_input)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfde5d17",
   "metadata": {},
   "source": [
    "- the model parameters in the autocast context remain float32\n",
    "- the output of first feed-forward layer is float16\n",
    "- the output of layer norm is float32\n",
    "- the output of the predicted logits fc2(x) is float16\n",
    "- the output of the loss should be float16\n",
    "- the gradients should be float32\n",
    "\n",
    "The layer norm remains as float32 because the mean and variance calculations can suffer signficant precision loss in float16. Small differences between large numbers (e.g., x - mean) can result in catastrophic cancellation. Division and square root operations are also numerically unstable in low precision. float16 only allocates 5 bits to the exponent, so it cannot represent extremely small or large values like float32.\n",
    "\n",
    "bfloat16 can represent very small or large values like float32 because it has 8-bits allocated to the exponent, the same as float32. With bfloat16 the layernorm shoudl be able to remain in bfloat16 rather than converting to float32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c293d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
