{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b612fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaab1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llm.transformer import TransformerLM\n",
    "from llm.tokenization import Tokenizer\n",
    "from llm.serialization import load_checkpoint\n",
    "from llm.generation import generateLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e651ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_pkl = \"/media/bryan/ssd01/expr/llm_from_scratch/tokenization/bpe_10k_tinystories.pkl\"\n",
    "eos_token = \"<|endoftext|>\"\n",
    "tokenizer = Tokenizer.from_pickle(tokenized_dataset_pkl, special_tokens=[eos_token])\n",
    "vocab_size = len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6490f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pth = \"/media/bryan/ssd01/expr/llm_from_scratch/tune-lr/1e-3/checkpoint_best.pt\"\n",
    "model = TransformerLM(\n",
    "    vocab_size=vocab_size,\n",
    "    context_length=256,\n",
    "    num_layers=4,\n",
    "    num_heads=16,\n",
    "    d_model=512,\n",
    "    d_ff=1344,\n",
    "    rope_theta=10000,\n",
    ")\n",
    "checkpoint = torch.load(model_pth)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207055d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLM(\n",
       "  (token_embeddings): Embedding(vocab_size=10000, d=512)\n",
       "  (RoPE): RotaryPositionalEmbedding(context_length=256, dim/2=16)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (attn): CausalMHSARoPE(\n",
       "        (qkv_proj): Linear(d_out=1536, d_in=512)\n",
       "        (output_proj): Linear(d_out=512, d_in=512)\n",
       "        (RoPE): RotaryPositionalEmbedding(context_length=256, dim/2=16)\n",
       "      )\n",
       "      (ffn): SwiGLU(\n",
       "        (w1): Linear(d_out=1344, d_in=512)\n",
       "        (w2): Linear(d_out=512, d_in=1344)\n",
       "        (w3): Linear(d_out=1344, d_in=512)\n",
       "      )\n",
       "      (ln1): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "      (ln2): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "  (lm_head): Linear(d_out=10000, d_in=512)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a19549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLM(\n",
       "  (token_embeddings): Embedding(vocab_size=10000, d=512)\n",
       "  (RoPE): RotaryPositionalEmbedding(context_length=256, dim/2=16)\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (attn): CausalMHSARoPE(\n",
       "        (qkv_proj): Linear(d_out=1536, d_in=512)\n",
       "        (output_proj): Linear(d_out=512, d_in=512)\n",
       "        (RoPE): RotaryPositionalEmbedding(context_length=256, dim/2=16)\n",
       "      )\n",
       "      (ffn): SwiGLU(\n",
       "        (w1): Linear(d_out=1344, d_in=512)\n",
       "        (w2): Linear(d_out=512, d_in=1344)\n",
       "        (w3): Linear(d_out=1344, d_in=512)\n",
       "      )\n",
       "      (ln1): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "      (ln2): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNorm(hidden_size=512, eps=1e-05)\n",
       "  (lm_head): Linear(d_out=10000, d_in=512)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a55704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:58: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:58: SyntaxWarning: invalid escape sequence '\\T'\n",
      "/home/bryan/src/LLM-from-scratch/llm/transformer.py:58: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "Once upon a time, there was a pretty girl named Lily. She loved to eat\n",
      "GENERATED:\n",
      "Once upon a time, there was a pretty girl named Lily. She loved to eat yummy food like apples, cheeseed pizza, and toasted cookies. One day, her mom said she had to leave the house to go and play. \n",
      "Lily was sad, but she knew that waiting would be back soon. She said goodbye to her mom and she went to play with her blocks. But when she got there, she could not find any delicious slices to eat. She started to cry. \n",
      "Lily went outside to look for more food but couldn't find any. She looked in the garden, but there was no yummy things. Suddenly, she saw a small hole in the fence. She tried to reach inside, but it was too far away. \n",
      "Lily had an idea. She put her hands and pulled out some of the small pieces. Then she ran back to the house and got the yummy cookies. From that day on, Lily made sure to close the door so she could get out safely.\n",
      "<|endoftext|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPTS = [\n",
    "#     \"Once upon a time there was a little boy named Ben. Ben loved to\",\n",
    "    \"Once upon a time, there was a pretty girl named Lily. She loved to eat\",\n",
    "]\n",
    "for prompt in PROMPTS:\n",
    "    generated_text = generateLLM(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        prompt,\n",
    "        max_new_tokens=256,\n",
    "        temperature=1.0,\n",
    "        top_k=25,\n",
    "        top_p=0.95,\n",
    "        eos_token=eos_token,\n",
    "        seed=42,\n",
    "    )\n",
    "    print_text = f\"PROMPT:\\n{prompt}\\nGENERATED:\\n{prompt}{generated_text}\\n\"\n",
    "    print(print_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36df9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token_id = tokenizer.encode(eos_token)\n",
    "eos_token_id.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8cdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
